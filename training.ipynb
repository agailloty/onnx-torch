{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import ImageDataset, compute_acc\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch, torch.nn as nn\n",
    "from torchvision.models import efficientnet_b3\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_folder = 'data/'\n",
    "# Define any image preprocessing steps you want to apply\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create an instance of the dataset\n",
    "train_dataset = ImageDataset(data_folder+'train', transform=transform)\n",
    "val_dataset = ImageDataset(data_folder+'valid', transform=transform)\n",
    "test_dataset = ImageDataset(data_folder+'test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class_labels_dict = {v: k for k, v in train_dataset.class_labels.items()}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:250\"\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 15\n",
    "# Use the dataset with a DataLoader to load the data in batches\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "model = efficientnet_b3(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the last layer with a custom layer with the number of outputs equal to the number of classes in your dataset\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "model.fc = nn.Linear(in_features=2048, out_features=num_classes).to(device)\n",
    "\n",
    "# to store model parameters during validation (early stopping)\n",
    "best_model = efficientnet_b3(pretrained=True).to(device)\n",
    "best_model.fc = nn.Linear(in_features=2048, out_features=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "show_every = 50\n",
    "\n",
    "# Keep track of the best validation loss\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "patience = 5\n",
    "num_no_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] Training loss: 8.379  Training acc: 0.000\n",
      "Epoch 0: Train Loss: 8.3792, Validation Loss: 8.7388, Train Accuracy: 0.00%, Validation Accuracy: 0.00%\n",
      "[2,     1] Training loss: 9.133  Training acc: 0.000\n",
      "Epoch 1: Train Loss: 9.1330, Validation Loss: 7.4698, Train Accuracy: 0.00%, Validation Accuracy: 0.00%\n",
      "[3,     1] Training loss: 7.606  Training acc: 0.000\n",
      "Epoch 2: Train Loss: 7.6063, Validation Loss: 6.7149, Train Accuracy: 0.00%, Validation Accuracy: 0.00%\n",
      "[4,     1] Training loss: 6.855  Training acc: 0.000\n",
      "Epoch 3: Train Loss: 6.8550, Validation Loss: 6.6123, Train Accuracy: 0.00%, Validation Accuracy: 0.39%\n",
      "[5,     1] Training loss: 6.605  Training acc: 0.000\n",
      "Epoch 4: Train Loss: 6.6049, Validation Loss: 6.5029, Train Accuracy: 0.00%, Validation Accuracy: 0.78%\n",
      "[6,     1] Training loss: 6.542  Training acc: 0.000\n",
      "Epoch 5: Train Loss: 6.5420, Validation Loss: 6.2633, Train Accuracy: 0.00%, Validation Accuracy: 1.57%\n",
      "[7,     1] Training loss: 6.230  Training acc: 0.000\n",
      "Epoch 6: Train Loss: 6.2303, Validation Loss: 5.9721, Train Accuracy: 0.00%, Validation Accuracy: 0.39%\n",
      "[8,     1] Training loss: 5.930  Training acc: 0.000\n",
      "Epoch 7: Train Loss: 5.9300, Validation Loss: 5.6719, Train Accuracy: 0.00%, Validation Accuracy: 0.78%\n",
      "[9,     1] Training loss: 5.755  Training acc: 0.000\n",
      "Epoch 8: Train Loss: 5.7548, Validation Loss: 5.4777, Train Accuracy: 0.00%, Validation Accuracy: 0.78%\n",
      "[10,     1] Training loss: 5.114  Training acc: 0.000\n",
      "Epoch 9: Train Loss: 5.1141, Validation Loss: 5.4495, Train Accuracy: 0.00%, Validation Accuracy: 1.37%\n",
      "[11,     1] Training loss: 4.956  Training acc: 0.000\n",
      "Epoch 10: Train Loss: 4.9564, Validation Loss: 5.5568, Train Accuracy: 0.00%, Validation Accuracy: 1.96%\n",
      "[12,     1] Training loss: 5.487  Training acc: 0.000\n",
      "Epoch 11: Train Loss: 5.4866, Validation Loss: 5.4177, Train Accuracy: 0.00%, Validation Accuracy: 1.76%\n",
      "[13,     1] Training loss: 5.535  Training acc: 0.000\n",
      "Epoch 12: Train Loss: 5.5347, Validation Loss: 5.3168, Train Accuracy: 0.00%, Validation Accuracy: 1.57%\n",
      "[14,     1] Training loss: 4.737  Training acc: 13.333\n",
      "Epoch 13: Train Loss: 4.7372, Validation Loss: 5.2756, Train Accuracy: 13.33%, Validation Accuracy: 1.57%\n",
      "[15,     1] Training loss: 5.209  Training acc: 6.667\n",
      "Epoch 14: Train Loss: 5.2088, Validation Loss: 6.6213, Train Accuracy: 6.67%, Validation Accuracy: 0.98%\n",
      "[16,     1] Training loss: 5.750  Training acc: 6.667\n",
      "Epoch 15: Train Loss: 5.7504, Validation Loss: 5.1817, Train Accuracy: 6.67%, Validation Accuracy: 1.37%\n",
      "[17,     1] Training loss: 5.033  Training acc: 0.000\n",
      "Epoch 16: Train Loss: 5.0331, Validation Loss: 5.1613, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[18,     1] Training loss: 5.607  Training acc: 0.000\n",
      "Epoch 17: Train Loss: 5.6067, Validation Loss: 5.1478, Train Accuracy: 0.00%, Validation Accuracy: 1.57%\n",
      "[19,     1] Training loss: 5.364  Training acc: 0.000\n",
      "Epoch 18: Train Loss: 5.3639, Validation Loss: 5.0900, Train Accuracy: 0.00%, Validation Accuracy: 1.18%\n",
      "[20,     1] Training loss: 5.143  Training acc: 6.667\n",
      "Epoch 19: Train Loss: 5.1433, Validation Loss: 5.0650, Train Accuracy: 6.67%, Validation Accuracy: 1.57%\n",
      "[21,     1] Training loss: 5.230  Training acc: 0.000\n",
      "Epoch 20: Train Loss: 5.2297, Validation Loss: 5.0661, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[22,     1] Training loss: 4.919  Training acc: 0.000\n",
      "Epoch 21: Train Loss: 4.9189, Validation Loss: 5.0427, Train Accuracy: 0.00%, Validation Accuracy: 1.18%\n",
      "[23,     1] Training loss: 4.875  Training acc: 0.000\n",
      "Epoch 22: Train Loss: 4.8755, Validation Loss: 5.0327, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[24,     1] Training loss: 4.845  Training acc: 6.667\n",
      "Epoch 23: Train Loss: 4.8448, Validation Loss: 5.0136, Train Accuracy: 6.67%, Validation Accuracy: 1.37%\n",
      "[25,     1] Training loss: 5.054  Training acc: 0.000\n",
      "Epoch 24: Train Loss: 5.0543, Validation Loss: 5.0146, Train Accuracy: 0.00%, Validation Accuracy: 1.37%\n",
      "[26,     1] Training loss: 5.178  Training acc: 0.000\n",
      "Epoch 25: Train Loss: 5.1785, Validation Loss: 4.9696, Train Accuracy: 0.00%, Validation Accuracy: 2.16%\n",
      "[27,     1] Training loss: 4.690  Training acc: 6.667\n",
      "Epoch 26: Train Loss: 4.6904, Validation Loss: 4.9441, Train Accuracy: 6.67%, Validation Accuracy: 1.18%\n",
      "[28,     1] Training loss: 4.787  Training acc: 6.667\n",
      "Epoch 27: Train Loss: 4.7868, Validation Loss: 4.9605, Train Accuracy: 6.67%, Validation Accuracy: 0.98%\n",
      "[29,     1] Training loss: 4.741  Training acc: 0.000\n",
      "Epoch 28: Train Loss: 4.7414, Validation Loss: 5.0027, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[30,     1] Training loss: 5.010  Training acc: 0.000\n",
      "Epoch 29: Train Loss: 5.0096, Validation Loss: 5.0093, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[31,     1] Training loss: 5.061  Training acc: 0.000\n",
      "Epoch 30: Train Loss: 5.0610, Validation Loss: 4.9481, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[32,     1] Training loss: 4.728  Training acc: 0.000\n",
      "Epoch 31: Train Loss: 4.7278, Validation Loss: 4.9103, Train Accuracy: 0.00%, Validation Accuracy: 1.57%\n",
      "[33,     1] Training loss: 4.577  Training acc: 0.000\n",
      "Epoch 32: Train Loss: 4.5770, Validation Loss: 4.9153, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[34,     1] Training loss: 4.758  Training acc: 0.000\n",
      "Epoch 33: Train Loss: 4.7576, Validation Loss: 4.9139, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[35,     1] Training loss: 4.916  Training acc: 0.000\n",
      "Epoch 34: Train Loss: 4.9163, Validation Loss: 4.8979, Train Accuracy: 0.00%, Validation Accuracy: 1.18%\n",
      "[36,     1] Training loss: 4.732  Training acc: 0.000\n",
      "Epoch 35: Train Loss: 4.7318, Validation Loss: 4.8999, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[37,     1] Training loss: 4.967  Training acc: 0.000\n",
      "Epoch 36: Train Loss: 4.9666, Validation Loss: 4.9092, Train Accuracy: 0.00%, Validation Accuracy: 1.37%\n",
      "[38,     1] Training loss: 5.078  Training acc: 0.000\n",
      "Epoch 37: Train Loss: 5.0779, Validation Loss: 4.9064, Train Accuracy: 0.00%, Validation Accuracy: 1.18%\n",
      "[39,     1] Training loss: 4.834  Training acc: 6.667\n",
      "Epoch 38: Train Loss: 4.8335, Validation Loss: 4.8897, Train Accuracy: 6.67%, Validation Accuracy: 0.98%\n",
      "[40,     1] Training loss: 4.932  Training acc: 0.000\n",
      "Epoch 39: Train Loss: 4.9319, Validation Loss: 4.8851, Train Accuracy: 0.00%, Validation Accuracy: 0.59%\n",
      "[41,     1] Training loss: 4.862  Training acc: 0.000\n",
      "Epoch 40: Train Loss: 4.8617, Validation Loss: 4.8741, Train Accuracy: 0.00%, Validation Accuracy: 0.98%\n",
      "[42,     1] Training loss: 4.827  Training acc: 6.667\n",
      "Epoch 41: Train Loss: 4.8266, Validation Loss: 4.8686, Train Accuracy: 6.67%, Validation Accuracy: 0.98%\n",
      "[43,     1] Training loss: 4.524  Training acc: 0.000\n",
      "Epoch 42: Train Loss: 4.5236, Validation Loss: 4.8888, Train Accuracy: 0.00%, Validation Accuracy: 1.76%\n",
      "[44,     1] Training loss: 4.881  Training acc: 0.000\n",
      "Epoch 43: Train Loss: 4.8811, Validation Loss: 4.9044, Train Accuracy: 0.00%, Validation Accuracy: 1.57%\n",
      "[45,     1] Training loss: 4.767  Training acc: 6.667\n",
      "Epoch 44: Train Loss: 4.7675, Validation Loss: 4.8976, Train Accuracy: 6.67%, Validation Accuracy: 1.57%\n",
      "[46,     1] Training loss: 4.691  Training acc: 13.333\n",
      "Epoch 45: Train Loss: 4.6908, Validation Loss: 4.9025, Train Accuracy: 13.33%, Validation Accuracy: 1.18%\n",
      "[47,     1] Training loss: 5.002  Training acc: 6.667\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(100):  # number of epochs\n",
    "\n",
    "    store_train_loss = []\n",
    "    store_train_acc = []\n",
    "    store_val_loss = []\n",
    "    store_val_acc = []\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_dataloader, 0):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # One-hot encode the labels\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc = compute_acc(outputs, labels)\n",
    "\n",
    "        # Print the statistics\n",
    "        store_train_loss.append(loss.item())\n",
    "        store_train_acc.append(train_acc)\n",
    "\n",
    "        if i % show_every == 0:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] Training loss: %.3f  Training acc: %.3f' % (epoch + 1, i + 1, np.mean(store_train_loss[-show_every:] \n",
    "            ) , np.mean(store_train_acc[-show_every:]) ))\n",
    "        break\n",
    "\n",
    "\n",
    "    # compute epoch loss and accuracy \n",
    "    train_losses.append(np.mean(store_train_loss))\n",
    "    train_accuracies.append(np.mean(store_train_acc))\n",
    "\n",
    "    # Evaluate the model on the validation set \n",
    "    model.eval()\n",
    "\n",
    "    for i, (val_images, val_labels) in enumerate(val_dataloader, 0):\n",
    "        val_images = val_images.to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_images)\n",
    "        val_loss = criterion(val_outputs, val_labels)\n",
    "        val_acc = compute_acc(val_outputs, val_labels)\n",
    "\n",
    "        # Print the statistics\n",
    "        store_val_loss.append(val_loss.item())\n",
    "        store_val_acc.append(val_acc)\n",
    "\n",
    "    mean_val_loss = np.mean(store_val_loss)\n",
    "        \n",
    "      #Check if validation loss has improved\n",
    "    if np.mean(mean_val_loss < best_val_loss):\n",
    "        best_val_loss = mean_val_loss\n",
    "        # Get the current state of the model\n",
    "        model_state_dict = model.state_dict()\n",
    "        best_model.load_state_dict(model_state_dict)\n",
    "        num_no_improvement = 0 \n",
    "    else:\n",
    "        num_no_improvement+=1 \n",
    "    if num_no_improvement == patience: \n",
    "        break\n",
    "\n",
    "    # compute epoch loss and accuracy \n",
    "    val_losses.append(np.mean(store_val_loss))\n",
    "    val_accuracies.append(np.mean(store_val_acc))\n",
    "\n",
    "    # Print loss and acc at the end of the epoch\n",
    "    print(\"Epoch {}: Train Loss: {:.4f}, Validation Loss: {:.4f}, Train Accuracy: {:.2f}%, Validation Accuracy: {:.2f}%\".format\n",
    "    (epoch, train_losses[-1], val_losses[-1], train_accuracies[-1], val_accuracies[-1]))\n",
    "\n",
    "   \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is:  0.9803921568627452\n"
     ]
    }
   ],
   "source": [
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "store_test_acc = []\n",
    "\n",
    "for i, (test_images, test_labels) in enumerate(test_dataloader, 0):\n",
    "    \n",
    "    test_images = test_images.to(device)\n",
    "    test_labels = test_labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_images)\n",
    "    test_acc = compute_acc(test_outputs, test_labels)\n",
    "\n",
    "    store_test_acc.append(test_acc)\n",
    "\n",
    "avg_test_accuracy = np.mean(store_test_acc)\n",
    "print(\"The test accuracy is: \", avg_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path(os.path.dirname(\".\")) / \"bestmodel.pt\"\n",
    "torch.save(best_model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6db2167fb4fcacd03f8bd02d15ab4c3ca7c480041d518a2530fbd4947c1ca8e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
